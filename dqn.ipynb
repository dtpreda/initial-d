{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 15:15:50.685719: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-20 15:15:50.753280: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-20 15:15:50.754552: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-20 15:15:52.439307: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from dqn import CarRacingAgent\n",
    "import gym\n",
    "from collections import deque\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RENDER = False\n",
    "START_EPISODE = 1\n",
    "END_EPISODE = 1000\n",
    "SKIP_FRAMES = 2\n",
    "BATCH_SIZE = 64\n",
    "SAVE_MODEL_EVERY = 25\n",
    "UPDATE_TARGET_MODEL_EVERY = 5\n",
    "NEGATIVE_REWARD_TOLERANCE_WINDOW = 100\n",
    "NEGATIVE_REWARD_TOLERANCE_LIMIT = 25\n",
    "SAVE_MODEL_PATH = './save/episode_{}.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v1')\n",
    "agent = CarRacingAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_state(state):\n",
    "    state = cv.cvtColor(state, cv.COLOR_RGB2GRAY)\n",
    "    state = state.astype(np.float32)\n",
    "    state /= 255.0\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deque_to_stack(deque):\n",
    "    frame_stack = np.array(deque)\n",
    "    # to channels last\n",
    "    return np.expand_dims(frame_stack, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Episode: 1/1000\n",
      "Track generation: 1159..1453 -> 294-tiles track\n",
      "Episode: 1/1000, Total Reward: -0.15, Epsilon: 1.0\n",
      "Starting Episode: 2/1000\n",
      "Track generation: 1122..1404 -> 282-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1084..1359 -> 275-tiles track\n",
      "Starting Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 15:16:01.870250: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 25267200 exceeds 10% of free system memory.\n",
      "2023-05-20 15:16:01.870299: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 25267200 exceeds 10% of free system memory.\n",
      "2023-05-20 15:16:01.873292: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 27992448 exceeds 10% of free system memory.\n",
      "2023-05-20 15:16:01.896842: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 25267200 exceeds 10% of free system memory.\n",
      "2023-05-20 15:16:01.896905: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 25267200 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 1.0\n",
      "epsilon: 0.9999\n",
      "epsilon: 0.9998000100000001\n",
      "epsilon: 0.9997000299990001\n",
      "epsilon: 0.9996000599960002\n",
      "epsilon: 0.9995000999900007\n",
      "epsilon: 0.9994001499800017\n",
      "epsilon: 0.9993002099650037\n",
      "epsilon: 0.9992002799440072\n",
      "epsilon: 0.9991003599160128\n",
      "epsilon: 0.9990004498800211\n",
      "epsilon: 0.9989005498350332\n",
      "epsilon: 0.9988006597800497\n",
      "epsilon: 0.9987007797140718\n",
      "epsilon: 0.9986009096361004\n",
      "epsilon: 0.9985010495451367\n",
      "epsilon: 0.9984011994401822\n",
      "epsilon: 0.9983013593202382\n",
      "Episode: 2/1000, Total Reward: -0.15, Epsilon: 1.0\n",
      "Starting Episode: 3/1000\n",
      "Track generation: 1093..1370 -> 277-tiles track\n",
      "epsilon: 0.9982015291843062\n",
      "epsilon: 0.9981017090313877\n",
      "epsilon: 0.9980018988604846\n",
      "epsilon: 0.9979020986705985\n",
      "epsilon: 0.9978023084607315\n",
      "epsilon: 0.9977025282298854\n",
      "epsilon: 0.9976027579770624\n",
      "epsilon: 0.9975029977012647\n",
      "epsilon: 0.9974032474014946\n",
      "epsilon: 0.9973035070767544\n",
      "epsilon: 0.9972037767260468\n",
      "epsilon: 0.9971040563483742\n",
      "epsilon: 0.9970043459427393\n",
      "epsilon: 0.9969046455081451\n",
      "epsilon: 0.9968049550435942\n",
      "epsilon: 0.9967052745480899\n",
      "epsilon: 0.9966056040206351\n",
      "epsilon: 0.9965059434602331\n",
      "epsilon: 0.9964062928658871\n",
      "epsilon: 0.9963066522366005\n",
      "epsilon: 0.9962070215713769\n",
      "epsilon: 0.9961074008692198\n",
      "epsilon: 0.9960077901291329\n",
      "epsilon: 0.9959081893501199\n",
      "epsilon: 0.995808598531185\n",
      "epsilon: 0.9957090176713319\n",
      "epsilon: 0.9956094467695648\n",
      "epsilon: 0.9955098858248879\n",
      "epsilon: 0.9954103348363054\n",
      "epsilon: 0.9953107938028217\n",
      "epsilon: 0.9952112627234414\n",
      "epsilon: 0.9951117415971691\n",
      "epsilon: 0.9950122304230093\n",
      "epsilon: 0.9949127291999671\n",
      "epsilon: 0.9948132379270471\n",
      "epsilon: 0.9947137566032545\n",
      "epsilon: 0.9946142852275941\n",
      "epsilon: 0.9945148237990713\n",
      "epsilon: 0.9944153723166914\n",
      "epsilon: 0.9943159307794598\n",
      "epsilon: 0.9942164991863819\n",
      "epsilon: 0.9941170775364633\n",
      "epsilon: 0.9940176658287097\n",
      "epsilon: 0.9939182640621268\n",
      "epsilon: 0.9938188722357206\n",
      "epsilon: 0.993719490348497\n",
      "epsilon: 0.9936201183994622\n",
      "epsilon: 0.9935207563876223\n",
      "Episode: 3/1000, Total Reward: -0.21, Epsilon: 0.99\n",
      "Starting Episode: 4/1000\n",
      "Track generation: 1107..1388 -> 281-tiles track\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStarting Training\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(agent\u001b[39m.\u001b[39mmemory) \u001b[39m>\u001b[39m BATCH_SIZE:\n\u001b[0;32m---> 47\u001b[0m     agent\u001b[39m.\u001b[39;49mreplay(BATCH_SIZE)\n\u001b[1;32m     48\u001b[0m time_frame_counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[39mif\u001b[39;00m time_frame_counter \u001b[39m%\u001b[39m \u001b[39m50\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/initial-d/dqn.py:82\u001b[0m, in \u001b[0;36mCarRacingAgent.replay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     79\u001b[0m states, actions, rewards, next_states, dones \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mminibatch)\n\u001b[1;32m     81\u001b[0m train_states \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39mtranspose(state[\u001b[39m0\u001b[39m], (\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m)) \u001b[39mfor\u001b[39;00m state \u001b[39min\u001b[39;00m states])\n\u001b[0;32m---> 82\u001b[0m train_targets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(train_states, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     84\u001b[0m next_states \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39mtranspose(state[\u001b[39m0\u001b[39m], (\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m)) \u001b[39mfor\u001b[39;00m state \u001b[39min\u001b[39;00m next_states])\n\u001b[1;32m     85\u001b[0m next_state_values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mamax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_model\u001b[39m.\u001b[39mpredict(next_states, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:2349\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2340\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m   2341\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   2342\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2343\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2346\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m   2347\u001b[0m         )\n\u001b[0;32m-> 2349\u001b[0m data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[1;32m   2350\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m   2351\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   2352\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps,\n\u001b[1;32m   2353\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m   2354\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m   2355\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   2356\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   2357\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   2358\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2359\u001b[0m     steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution,\n\u001b[1;32m   2360\u001b[0m )\n\u001b[1;32m   2362\u001b[0m \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   2363\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/data_adapter.py:1583\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(kwargs[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39m_cluster_coordinator\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1582\u001b[0m     \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1583\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/data_adapter.py:1260\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1257\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[1;32m   1259\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1260\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[1;32m   1261\u001b[0m     x,\n\u001b[1;32m   1262\u001b[0m     y,\n\u001b[1;32m   1263\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   1264\u001b[0m     steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   1265\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs \u001b[39m-\u001b[39;49m initial_epoch,\n\u001b[1;32m   1266\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1267\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   1268\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1269\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1270\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1271\u001b[0m     distribution_strategy\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mget_strategy(),\n\u001b[1;32m   1272\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1273\u001b[0m )\n\u001b[1;32m   1275\u001b[0m strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n\u001b[1;32m   1277\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/data_adapter.py:307\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m indices\n\u001b[1;32m    302\u001b[0m \u001b[39m# We prefetch a single element. Computing large permutations can take\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[39m# quite a while so we don't want to wait for prefetching over an epoch\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[39m# boundary to trigger the next permutation. On the other hand, too many\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[39m# simultaneous shuffles can contend on a hardware level and degrade all\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[39m# performance.\u001b[39;00m\n\u001b[0;32m--> 307\u001b[0m indices_dataset \u001b[39m=\u001b[39m indices_dataset\u001b[39m.\u001b[39;49mmap(permutation)\u001b[39m.\u001b[39mprefetch(\u001b[39m1\u001b[39m)\n\u001b[1;32m    309\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mslice_batch_indices\u001b[39m(indices):\n\u001b[1;32m    310\u001b[0m     \u001b[39m\"\"\"Convert a Tensor of indices into a dataset of batched indices.\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \n\u001b[1;32m    312\u001b[0m \u001b[39m    This step can be accomplished in several ways. The most natural is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[39m      A Dataset of batched indices.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:2240\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2236\u001b[0m \u001b[39m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2237\u001b[0m \u001b[39m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2238\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2239\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2240\u001b[0m \u001b[39mreturn\u001b[39;00m map_op\u001b[39m.\u001b[39;49m_map_v2(\n\u001b[1;32m   2241\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2242\u001b[0m     map_func,\n\u001b[1;32m   2243\u001b[0m     num_parallel_calls\u001b[39m=\u001b[39;49mnum_parallel_calls,\n\u001b[1;32m   2244\u001b[0m     deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[1;32m   2245\u001b[0m     name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py:37\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m debug_mode\u001b[39m.\u001b[39mDEBUG_MODE:\n\u001b[1;32m     35\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m`num_parallel_calls` argument is specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m   \u001b[39mreturn\u001b[39;00m _MapDataset(\n\u001b[1;32m     38\u001b[0m       input_dataset, map_func, preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m     39\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m   \u001b[39mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[1;32m     41\u001b[0m       input_dataset,\n\u001b[1;32m     42\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m       name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py:107\u001b[0m, in \u001b[0;36m_MapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_inter_op_parallelism \u001b[39m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m    106\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality \u001b[39m=\u001b[39m preserve_cardinality\n\u001b[0;32m--> 107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[1;32m    108\u001b[0m     map_func,\n\u001b[1;32m    109\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(),\n\u001b[1;32m    110\u001b[0m     dataset\u001b[39m=\u001b[39;49minput_dataset,\n\u001b[1;32m    111\u001b[0m     use_legacy_function\u001b[39m=\u001b[39;49muse_legacy_function)\n\u001b[1;32m    112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m name\n\u001b[1;32m    113\u001b[0m variant_tensor \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39mmap_dataset(\n\u001b[1;32m    114\u001b[0m     input_dataset\u001b[39m.\u001b[39m_variant_tensor,  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39mfunction\u001b[39m.\u001b[39mcaptured_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality,\n\u001b[1;32m    119\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_common_args)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:261\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    255\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    259\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[1;32m    262\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:232\u001b[0m, in \u001b[0;36mTracingCompiler.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    224\u001b[0m   \u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \n\u001b[1;32m    226\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39m      `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m   concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\n\u001b[1;32m    233\u001b[0m       \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    234\u001b[0m   concrete_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    235\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:202\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mmake_canonicalized_monomorphic_type(args, kwargs)\n\u001b[1;32m    201\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m--> 202\u001b[0m   concrete_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_concrete_function(args, kwargs)\n\u001b[1;32m    203\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m    204\u001b[0m   concrete_function\u001b[39m.\u001b[39m_arg_keywords \u001b[39m=\u001b[39m []  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:166\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m   args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature\n\u001b[1;32m    164\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 166\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m   args \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39margs\n\u001b[1;32m    394\u001b[0m kwargs \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39mkwargs\n\u001b[0;32m--> 396\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_concrete_function(\n\u001b[1;32m    397\u001b[0m     args, kwargs, func_graph)\n\u001b[1;32m    399\u001b[0m \u001b[39m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m graph_capture_container \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_function_captures  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:300\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m   arg_names \u001b[39m=\u001b[39m base_arg_names\n\u001b[1;32m    299\u001b[0m concrete_function \u001b[39m=\u001b[39m monomorphic_function\u001b[39m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 300\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m    301\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m    302\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m    303\u001b[0m         args,\n\u001b[1;32m    304\u001b[0m         kwargs,\n\u001b[1;32m    305\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    306\u001b[0m         func_graph\u001b[39m=\u001b[39;49mfunc_graph,\n\u001b[1;32m    307\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m    308\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m    309\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m    310\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value,\n\u001b[1;32m    311\u001b[0m         create_placeholders\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m    312\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m    313\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m    314\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    319\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1212\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1214\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1216\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:238\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39m@eager_function\u001b[39m\u001b[39m.\u001b[39mdefun_with_attributes(\n\u001b[1;32m    233\u001b[0m     input_signature\u001b[39m=\u001b[39mstructure\u001b[39m.\u001b[39mget_flat_tensor_specs(\n\u001b[1;32m    234\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_structure),\n\u001b[1;32m    235\u001b[0m     autograph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    236\u001b[0m     attributes\u001b[39m=\u001b[39mdefun_kwargs)\n\u001b[1;32m    237\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs):  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m   ret \u001b[39m=\u001b[39m wrapper_helper(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    239\u001b[0m   ret \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_tensor_list(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    240\u001b[0m   \u001b[39mreturn\u001b[39;00m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:169\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    168\u001b[0m   nested_args \u001b[39m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 169\u001b[0m ret \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39;49mtf_convert(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func, ag_ctx)(\u001b[39m*\u001b[39;49mnested_args)\n\u001b[1;32m    170\u001b[0m ret \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[1;32m    171\u001b[0m \u001b[39mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:376\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_unsupported(f):\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m--> 376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39;49mis_allowlisted(f):\n\u001b[1;32m    377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/conversion.py:146\u001b[0m, in \u001b[0;36mis_allowlisted\u001b[0;34m(o, check_call_override, allow_namedtuple_subclass)\u001b[0m\n\u001b[1;32m    144\u001b[0m       \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[39melif\u001b[39;00m action \u001b[39m==\u001b[39m config\u001b[39m.\u001b[39mAction\u001b[39m.\u001b[39mDO_NOT_CONVERT:\n\u001b[0;32m--> 146\u001b[0m       logging\u001b[39m.\u001b[39;49mlog(\u001b[39m2\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mAllowlisted: \u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m: \u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m'\u001b[39;49m, o, rule)\n\u001b[1;32m    147\u001b[0m       \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39m# The check for __code__ below is because isgeneratorfunction crashes\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39m# without one.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/utils/ag_logging.py:134\u001b[0m, in \u001b[0;36mlog\u001b[0;34m(level, msg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[39mif\u001b[39;00m echo_log_to_stdout:\n\u001b[1;32m    131\u001b[0m       _output_to_stdout(\u001b[39m'\u001b[39m\u001b[39mERROR: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m msg, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog\u001b[39m(level, msg, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    135\u001b[0m   \u001b[39mif\u001b[39;00m has_verbosity(level):\n\u001b[1;32m    136\u001b[0m     logging\u001b[39m.\u001b[39minfo(msg, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for episode in range(START_EPISODE, END_EPISODE + 1):\n",
    "    print(f\"Starting Episode: {episode}/{END_EPISODE}\")\n",
    "    initial_state = env.reset()\n",
    "    initial_state = process_state(initial_state)\n",
    "\n",
    "    total_reward = 0\n",
    "    negative_reward_count = 0\n",
    "    state_stack = deque([initial_state]*agent.frame_stack_num,maxlen=agent.frame_stack_num)\n",
    "    time_frame_counter = 1\n",
    "    done = False\n",
    "    #agent.memory = agent.build_memory()\n",
    "\n",
    "    while True:\n",
    "        if RENDER:\n",
    "            env.render()\n",
    "        \n",
    "        current_state_stack = deque_to_stack(state_stack)\n",
    "        action = agent.act(current_state_stack)\n",
    "\n",
    "        reward = 0\n",
    "        for _ in range(SKIP_FRAMES + 1):\n",
    "            next_state, step_reward, done, _ = env.step(action)\n",
    "            reward += step_reward\n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        negative_reward_count += 1 if time_frame_counter > NEGATIVE_REWARD_TOLERANCE_WINDOW and reward < 0 else 0\n",
    "\n",
    "        # we can increase rewards here for specific actions to encourage the agent to learn them\n",
    "\n",
    "        total_reward += reward\n",
    "\n",
    "        next_state = process_state(next_state)\n",
    "        state_stack.append(next_state)\n",
    "        next_state_stack = deque_to_stack(state_stack)\n",
    "\n",
    "        agent.remember(current_state_stack, action, reward, next_state_stack, done)\n",
    "\n",
    "        if done or negative_reward_count > NEGATIVE_REWARD_TOLERANCE_LIMIT or total_reward < 0:\n",
    "            print(f\"Episode: {episode}/{END_EPISODE}, Total Reward: {total_reward:.2}, Epsilon: {agent.epsilon:.2}\")\n",
    "            break\n",
    "\n",
    "        if len(agent.memory) == BATCH_SIZE:\n",
    "            print(\"Starting Training\")\n",
    "        \n",
    "        if len(agent.memory) > BATCH_SIZE:\n",
    "            agent.replay(BATCH_SIZE)\n",
    "        time_frame_counter += 1\n",
    "\n",
    "        if time_frame_counter % 50 == 0:\n",
    "            print(f\"Episode: {episode}/{END_EPISODE}, Iteration:{time_frame_counter}, Total Reward: {total_reward:.2}, Epsilon: {agent.epsilon:.2}\")\n",
    "    \n",
    "    if episode % UPDATE_TARGET_MODEL_EVERY == 0:\n",
    "        agent.update_target_model()\n",
    "    \n",
    "    if episode % SAVE_MODEL_EVERY == 0:\n",
    "        agent.save_model(SAVE_MODEL_PATH.format(episode))\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
